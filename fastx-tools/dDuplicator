#! /usr/bin/env python

# Originally written by Adrienne Norrell and Dr. Ken Jones (U.C Denver)
# ported to python3, updated, enhanced with plotting, and optimized by Pavel Dimens
# this version is for EcoRI + MspI ddRAD sequences when the read structure is:
# read1 = 1-8 UMI, 9-13 EcoRI cutsite (AATTC), 14-151 read
# read2 = 1-3 MspI cutsite (CGG), 4-151 read

def usage():
    print("\nThis py3 script finds and removes UMI elements between paired-end reads")
    print("  - File format must be <name>.<F/R1>.<fastq/fq>.gz and <name>.<R/R2>.<fastq/fq>.gz")
    print("    -  e.g. grizzlybear_001.F.fq.gz and grizzlybear_001.R.fq.gz")
    print("  - Configured for 2x150bp ddRAD sequences using EcoRI + MspI & 8bp UMI")
    print("\n[usage] dDuplicator <number.of.cores>")
    print("[example] dDupilcator 10", "\n")

import sys

if len(sys.argv) != 2:
    usage()
    exit()
else:
    from bokeh.io import save, output_file
    from bokeh.models import HoverTool
    from bokeh.plotting import figure, ColumnDataSource
    import pandas as pd
    from multiprocessing import Pool
    from Bio.SeqIO.QualityIO import *
    from Bio import SeqIO
    import shutil
    import glob
    import fileinput
    import gzip
    import os


#pull out all the files
filelist_fastq = glob.glob(os.getcwd() + '/*fastq.gz')
filelist_fq = glob.glob(os.getcwd() + '/*fq.gz')

# sanity checks
if len(filelist_fastq) == 0 and len(filelist_fq) == 0 :
    print("Error: Files ending in .fastq.gz or .fq.gz not found")
    exit()
# found .fq.gz
if len(filelist_fastq) == 0 and len(filelist_fq) > 0 :
    filelist = filelist_fq
    ext_type = ".fq.gz"
# found .fastq.gz
elif len(filelist_fastq) > 0 and len(filelist_fq) == 0 :
    filelist = filelist_fastq
    ext_type = ".fastq.gz"
else:
    print("Error: Directory contains files ending in both .fq.gz and .fastq.gz")
    exit()

# final sanity check that file list has even number of files
if (len(filelist) % 2) != 0 :
    print("Error: Odd number of reads founds. Expects paired-end reads,\nmeaning there should be an even number of files detected")
    exit()

# get just the file names
filelist = sorted([os.path.basename(i) for i in filelist])
# partition file list into pairs of forward and reverse reads
read_pairs = [filelist[i:i + 2] for i in range(0, len(filelist), 2)]

print("- Found " + str(len(read_pairs)) + " read pairs ending with " + ext_type)

reportfilename = "deduplicated/UMI_report.csv"
os.makedirs(os.path.dirname(reportfilename), exist_ok=True)
umi_fldr = "deduplicated/"
with open(reportfilename, "w") as f:
    f.write("Filename" + "\t" + "Good Pairs" + "\t" +
            "Duplicates" + "\t" + "Proportion Duplicates" + "\n")

print("Processing:")
def processUMI(infile):

    good_pairs = 0
    duplicates = 0
    # first file in the pair
    filename1 = infile[0]
    # second file in the pair
    filename2 = infile[1]
    # the basename stripped of the extension
    filebase = filename1.split(".")[0]

    print(filebase)

    forward_names = []
    reverse_names = []
    forward_seqs = []
    forward_quals = []
    reverse_seqs = []
    reverse_quals = []

    f_iter = FastqGeneralIterator(gzip.open(filename1, "rt"))
    r_iter = FastqGeneralIterator(gzip.open(filename2, "rt"))
    for (f_id, f_seq, f_q), (r_id, r_seq, r_q) in zip(f_iter, r_iter):

        UMI = f_seq[0:8]
        seq1 = f_seq[13:]
        seq2 = r_seq[5:]
        qual1 = f_q[13:]
        qual2 = r_q[5:]
        good_seq1 = 0
        good_seq2 = 0

        try:
            # while loop:  runs until a defined condition is met.  If the last value in qual1 < 30 or the second to last is < 30, or the third to last is < 30, then the last element in seq1 and qual1 will be deleted and the loop will run again (-1 element of qual1, so the loop is moving backwards through the string). The condition is met when the last three values are greater than 30.  At this point, the loop stops running, and if the length of seq1 is greater than or equal to 75, it is considered a good sequence.

            # Why 33?  33 is an adjustment factor.  The ASCII code (what we get when we use the ord command) is offset from phred scores by 33 points. "To convert a symbol to a numerical phred score, subtract 33 from the ASCII symbol's decimal value." -prognosisbio.com
            while ord(qual1[len(qual1)-1]) - 33 < 30 or ord(qual1[len(qual1)-2]) - 33 < 30 or ord(qual1[len(qual1)-3]) - 33 < 30:
                seq1 = seq1[:len(seq1)-1]
                qual1 = qual1[:len(qual1)-1]

            if len(seq1) >= 75:
                good_seq1 = 1

            while ord(qual2[len(qual2)-1]) - 33 < 30 or ord(qual2[len(qual2)-2]) - 33 < 30 or ord(qual2[len(qual2)-3]) - 33 < 30:
                seq2 = seq2[:len(seq2)-1]
                qual2 = qual2[:len(qual2)-1]

            if len(seq2) >= 75:
                good_seq2 = 1

    # If both read 1 and read 2 have a length greater than 75, then the both of them make a good pair and the information is appended to the empty lists that were made earlier.
            if good_seq1 == 1 and good_seq2 == 1:
                good_pairs = good_pairs + 1

                forward_names.append(f_id)
                reverse_names.append(r_id)
                forward_seqs.append(UMI + seq1)
                forward_quals.append(qual1)
                reverse_seqs.append(seq2)
                reverse_quals.append(qual2)
    # If the 1 or both of the sequences were bad, then bad_seq = 1
        except:
            bad_seq = 1

    f_iter.close()
    r_iter.close()

    nondup_fseqs = []
    seen = set()
    nondup_rseqs = []
    nondup_rquals = []
    nondup_fquals = []
    nondup_fnames = []
    nondup_rnames = []
    for i, val in enumerate(forward_seqs):
        if val[:76] not in seen:
            nondup_fseqs.append(val)
            nondup_fquals.append(forward_quals[i])
            nondup_fnames.append(forward_names[i])
            nondup_rseqs.append(reverse_seqs[i])
            nondup_rquals.append(reverse_quals[i])
            nondup_rnames.append(reverse_names[i])
            seen.add(val[:76])
        else:
            duplicates = duplicates + 1

    outfilename1 = filebase + ".dedup.F.fq.gz"  # rename output file1
    outfilename2 = filebase + ".dedup.R.fq.gz"  # rename outpu file 2
    outfile1 = gzip.open(umi_fldr + outfilename1, "wt", compresslevel=5)
    outfile2 = gzip.open(umi_fldr + outfilename2, "wt", compresslevel=5)

    for a in range(len(nondup_fseqs)):

        outfile1.write("@" + nondup_fnames[a]
                       + "\n" + nondup_fseqs[a][8:]
                       + "\n" + "+"
                       + "\n" + nondup_fquals[a]
                       + "\n")
        outfile2.write("@" + nondup_rnames[a]
                       + "\n" + nondup_rseqs[a][8:]
                       + "\n" + "+"
                       + "\n" + nondup_rquals[a][8:]
                       + "\n")
    outfile1.close()
    outfile2.close()

    umifile = open(umi_fldr + "UMI_report.csv", "a")
    umifile.write(str(filebase)
                  + "\t" + str(good_pairs)
                  + "\t" + str(duplicates)
                  + "\t" + str(round(duplicates/good_pairs, 2))
                  + "\n")

    umifile.close()


if __name__ == '__main__':
    pool = Pool(int(sys.argv[1]))
    pool.map(processUMI, read_pairs)


def umiplot():

    df = pd.read_csv("deduplicated/UMI_report.csv", sep='\t', header=0,
                     names=["filename", "good", "dupes", "proportion"])
    output_file("deduplicated/UMI_report.html")

    data = {
        'filename': df.filename,
        'Good': df.good,
        'Duplicates': df.dupes,
        'props': df.proportion}

    TOOLTIPS = [
        ("Filename", "@filename"),
        ("Good Pairs", "@Good"),
        ("Duplicates", "@Duplicates"),
        ("Proportion Duplicates", "@props{(0.00)}"),
    ]
    readstype = ['Good', 'Duplicates']
    p = figure(x_range=df.filename, sizing_mode='stretch_both',
               title="RAD UMI duplicates report", toolbar_location=None)
    p.vbar_stack(readstype, x='filename', source=data, width=0.8, color=['#0099cc', '#e84d60'],
                 hover_fill_color=['#006b8e', '#a23543'], hover_line_color=['#006b8e', '#a23543'])

    p.min_border = 50
    p.xgrid.grid_line_color = None
    p.background_fill_color = "#f5f5f5"
    p.y_range.start = 0
    p.axis.axis_line_color = None
    p.yaxis.axis_label = 'Number of Reads'
    p.left[0].formatter.use_scientific = False
    p.xaxis.visible = True
    # p.axis.minor_tick_line_color = None
    p.add_tools(HoverTool(tooltips=TOOLTIPS, mode='mouse'))
    save(filename='deduplicated/UMI_report.html', title="RAD UMI duplicates report", obj=p)


umiplot()
print("\n\n--- processed reads and report are located in /deduplicated/ ---")
